{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvest Social media data (Twitter) \n",
    "## I REST my case\n",
    "### Learning outcomes\n",
    "\n",
    "Data from social media such as Twitter, Flickt, Instagram etc. potentially is a rich source of spatial information.\n",
    "\n",
    "During this exercise you learn to apply python to:\n",
    "- connect to Twitter using the Twython package\n",
    "- fire a query to Twitter\n",
    "- parse the results and write it to a file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Twitter\n",
    "\n",
    "The next thing is that we need access to Twitter data To do this you have to:\n",
    "\n",
    "1. log in using your Twitter account (create one if you don't have)\n",
    "2. go to https://apps.twitter.com/ and create a new app by filling in the fields\n",
    "3. The result of creating (actually registering) a new app is that key (codes) are generated which allow you to acces the Twitter API (if you don't know what API still means google it)\n",
    "\n",
    "After you have obtained you acess code to twitter we can start coding a script in python giving us access to Twitter\n",
    "\n",
    "The first thing to do is import the neccesary libraries. The most important libraries you need are Twython and json. Have at look at the Twython website and answer to your self what is does.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run the code below: if you don't get an error message the Twython libraries are installed properly. If not open a terminal and install using pip ( pip install twython) or easy intstall ( easy_install twython). More info [here](https://twython.readthedocs.org/en/latest/usage/install.html#pip-or-easy-install)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import json\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json\n",
    "\n",
    "Before we start the real thing you have to understand something about JSON. JSON is an important data format for many web applications. Also Twitter makes use of JSON. It is a lightweight alternative for XML Make sure that you understand what JSON means and how it structures data: https://en.wikipedia.org/wiki/JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Twitter using Twython\n",
    "\n",
    "As mentioned Twython is the library that we use to connect to Twitter. Twitter offers two APIs: The REST api and the streaming API. \n",
    "\n",
    "The REST APIs provide programmatic access to read and write Twitter data. Author a new Tweet, read author profile and follower data, and more. The responses are available in JSON. Have a look a https://dev.twitter.com/rest/public to have a glace of what is offered\n",
    "\n",
    "If you want real-time (ok almost real-time) access to tweets you can use the STREAMING api. The Streaming APIs give developers low latency access to Twitter’s global stream of Tweet data. See for more information: https://dev.twitter.com/streaming/overview\n",
    "\n",
    "In this example we are going to use the REST api to fire some queries to Twitter, process the JSON response to extract from it what we need, and write it to a simple text file we can use to import in excell, a database, or even a GIS package. \n",
    "\n",
    "First of all instantiate a Twython object using the follwing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## (comments JV: here you need to fill in your own key?!)\n",
    "\n",
    "##codes to access twitter API. \n",
    "APP_KEY = 'J0x4IMB3vCfgOOsXvxIZeOuPH'\n",
    "APP_SECRET = 'yHbnCVFLtJ0judgkxUlyvliUO6dl6MOzBjDvPfZCKHQilnnsx4'\n",
    "OAUTH_TOKEN = '4492998268-4wETpb00W1xRci4VqDQGtY4vz6WpTJ4tq87PqY0'\n",
    "OAUTH_TOKEN_SECRET = '5Jsqc0QVFWB7w31ROPKzOpoJaRpzMlk91qksytjW6NaP4'\n",
    "\n",
    "##initiating Twython object \n",
    "twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "##this is just to provide some output if the connection is succesfull\n",
    "##twitter.verify_credentials()\n",
    "\n",
    "\n",
    "##TODO:  This should work as an alternative but it doesn't. Need to find out why\n",
    "#twitter = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "#ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "#print ACCESS_TOKEN\n",
    "#twitter = Twython(APP_KEY, access_token=ACCESS_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire a question to Twitter\n",
    "\n",
    "Ok we have connection (at least if you filled in youre credentials correctly). Now lets ask Twitter a simple question. For that we use the Twitter search API (which is part of the REST api). You can find documentation at https://dev.twitter.com/rest/public/search.\n",
    "\n",
    "The results of the query we store in a variable called search_results (but you might call it whatever you want)\n",
    "\n",
    "Have a look at the code below: what are you looking for, how many results are you getting back and in what type of data do you expect to be stored in the search_result variable?\n",
    "\n",
    "Ok run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "search_results = twitter.search(q='#amsterdam', count=10)\n",
    "\n",
    "\n",
    "#for result in results:\n",
    "#    print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get it out of JSON\n",
    "\n",
    "Nasty isn' t it? Just plain JSON containing a lot of information about the user, the location, the tweet. Have a look at https://dev.twitter.com/overview/api/tweets to get an overview what information is present in a tweet and how it is structured.\n",
    "\n",
    "Have a look at the code below. Our task is to get those data we are interested in. The tweet information is available in \"statuses\". So what we have to do is loop over all results, store each seperate tweet in a variable (in this case called tweet) and extract specific JSON fields from the tweet. Not so difficult provided that you know what you are looking for and where it is located. The thing is the JSON is a nested structure having various levels. The structure you can study at https://dev.twitter.com/overview/api/tweets. In the code below you see how to get it using Python. It helps to realize that the tweet is basically represented in Python as a dictionary with keys and values (thank to the Twyton and json libraries we imported)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wendywisest\n",
      "1554\n",
      "RT @JeffTitelius: How fun!! @velvetescape\n",
      "It's National Tulip Day! Free tulips for everyone on Dam Square #Amsterdam #tijdvoortulpen https:…\n",
      "===========================\n",
      "Amsterdam_nt\n",
      "1310\n",
      "#amsterdam De Bakker strijdend ten onder in Melbourne https://t.co/UQUDPhUOgy #nieuwstwitter\n",
      "===========================\n",
      "Hanebalk\n",
      "306\n",
      "RT @afwc1917: Woningcorporaties #Amsterdam waarschuwen voor nepsites waar vrije sector huurwoningen ongeoorloofd worden aangeboden https://…\n",
      "===========================\n",
      "pjpfollowme\n",
      "287\n",
      "#amsterdam De Bakker strijdend ten onder in Melbourne https://t.co/JRVI8Tdqv0 #nieuwstwitter\n",
      "===========================\n",
      "wx_amsterdam\n",
      "232\n",
      "#Amsterdam Jan 18 11:55 Temperature -1C fair Wind SE 15 km/h  Humidity 75% Netherlands .. https://t.co/PXjsAnHO7y\n",
      "===========================\n",
      "PlusBijbaan\n",
      "92\n",
      "#baan #jouwbaan #amsterdam Verkoopmedewerk(st)er oostelijke handels... bij Kruidvat https://t.co/uXsatbUBZQ\n",
      "===========================\n",
      "iMe_Angela\n",
      "551\n",
      "Can you recommend anyone for this #job? (Junior) Sales Engineer - https://t.co/lIjSWSrTfy #Amsterdam #ProjectMgmt… https://t.co/mPMYxx2Ny2\n",
      "===========================\n",
      "PocketVacations\n",
      "567\n",
      "EquinixJobs Can you recommend anyone for this #job? (Junior) Sales Engineer - https://t.co/h3gHjEYD3R #Amsterdam #ProjectMgmt #Hiring\n",
      "\n",
      "Can…\n",
      "===========================\n",
      "MissViloria\n",
      "223\n",
      "-3* y segunda infección de oído en lo que va de año. #Caloret #Amsterdam\n",
      "===========================\n",
      "OISPG\n",
      "2721\n",
      "#OI2Conf16 coming up in May! Save the date: 23/24 in #Amsterdam #OpenInnovation #OI2 #SmartCities #LivingLabs https://t.co/MzWa09aiq2\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "##parsing out \n",
    "for tweet in search_results[\"statuses\"]:\n",
    "    username =  tweet['user']['screen_name']\n",
    "    followers_count =  tweet['user']['followers_count']\n",
    "    tweettext = tweet['text']\n",
    "    if tweet['place'] != None:\n",
    "        full_place_name = tweet['place']['full_name']\n",
    "        place_type =  tweet['place']['place_type']    \n",
    "    coordinates = tweet['coordinates']\n",
    "    if coordinates != None:\n",
    "        print \"oki\"\n",
    "        #enter code her to pull out coordinate\n",
    "        \n",
    "    print username\n",
    "    print followers_count\n",
    "    print tweettext\n",
    "    #add some some output statements that print lat lon if present\n",
    "    print '==========================='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get it out of Python\n",
    "\n",
    "So ok, now you know. The only thing your have to do now is to make it last. In other words write it to a file so you can use your results in other software to analyse. The most simple thing to do is to adapt the code above so it write to a delimited file (comma or tab). If you use a comma delimited file make sure that your replace existing commas in the tweet text by something else (or by nothing). Otherwise you will shrew-up the datastructure of your file. The code sniplet below gives some hints. Try to interlace it yourself with the code above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = 'result.csv' \n",
    "\n",
    "\n",
    "target = open(output_file, 'a')\n",
    "\n",
    "\n",
    "target.write(username) # t is \n",
    "target.write('\\n') #produce a tab delimited file\n",
    "target.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
